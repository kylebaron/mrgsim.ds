---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = ".",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
using.parallel <- requireNamespace("mirai", quietly = TRUE)
```

# mrgsim.ds

<!-- badges: start -->
[![R-universe version](https://kylebaron.r-universe.dev/mrgsim.ds/badges/version)](https://kylebaron.r-universe.dev/mrgsim.ds)
[![r-universe status](https://kylebaron.r-universe.dev/mrgsim.ds/badges/checks)](https://kylebaron.r-universe.dev/mrgsim.ds)
[![R-CMD-check](https://github.com/kylebaron/mrgsim.ds/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/kylebaron/mrgsim.ds/actions/workflows/R-CMD-check.yaml)
<!-- badges: end -->


`mrgsim.ds` provides an [Apache Arrow](https://arrow.apache.org/docs/r/)-backed 
simulation output object for [mrgsolve](https://mrgsolve.org), greatly reducing 
the memory footprint of large simulations and providing a high-performance 
pipeline for summarizing huge simulation outputs. The arrow-based simulation 
output objects in R claim ownership of their files on disk. 
Those files are automatically removed when the owning object goes out of scope 
and becomes subject to the R garbage collector. While "anonymous", 
parquet-formatted files hold the data in `tempdir()` as you are working in 
R, functions are provided to move this data to more permanent locations for 
later use. 


## Installation

You can install the development version of `mrgsim.ds` from 
[r-universe](https://kylebaron.r-universe.dev/mrgsim.ds) with:

``` r
# Install 'mrgsim.ds' in R:
install.packages('mrgsim.ds', repos = c('https://kylebaron.r-universe.dev', 'https://cloud.r-project.org'))
```

## Example 

We will illustrate `mrgsim.ds` by doing a simulation. 

```{r, message = FALSE}
library(mrgsim.ds)
library(dplyr)

mod <- modlib_ds("popex", end = 240, outvars = "IPRED,CL")

data <- expand.ev(amt = 100, ii = 24, total = 6, ID = 1:3000)
```

`mrgsim.ds` provides a new `mrgsim()` variant - `mrgsim_ds()`. The name implies 
we are tapping into Apache Arrow 
[Dataset](https://arrow.apache.org/docs/r/reference/Dataset.html) functionality.
The simulation below carries `1,446,000` rows.

```{r}
out <- mrgsim_ds(mod, data)

out
```


## Very lightweight simulation output object

The output object doesn't actually carry these 1.4M rows of simulated data. 
Rather it stores a pointer to the data in parquet files on your disk.


```{r}
basename(out$files)
```

This means there is almost nothing inside the object itself

```{r}
lobstr:::obj_size(out)

dim(out)
```

What if we did the same simulation with regular `mrgsim()`?

```{r}
x <- mrgsim(mod, data)

lobstr::obj_size(x)

dim(x)
```


The `mrgsim.ds` object is very light weight despite tracking the same data. 

## Handles like regular mrgsim output

But, we can do a lot of the typical things we would with any `mrgsim()` output 
object. 


```{r plot_head_tail_dim, fig.height = 4, fig.width = 7, out.width = "80%", fig.align = "center"}
plot(out, nid = 12)

head(out)

tail(out)

dim(out)
```

This includes coercing to different types of objects. We can get the usual 
R data frames

```{r}
as_tibble(out)
```


Or stay in the arrow ecosystem

```{r}
as_arrow_ds(out)
```

Or try your hand at duckdb

```{r}
as_duckdb_ds(out)
```


## Tidyverse-friendly

We've integrated into the `dplyr` ecosystem as well, allowing you to `filter()`, 
`group_by()`, `mutate()`, `select()`, `summarise()`, `rename()`, or `arrange()` 
your way directly into a pipeline to summarize your simulations using the power 
of Apache Arrow.

```{r}
dd <- 
  out %>% 
  group_by(time) %>% 
  summarise(Mean = mean(IPRED, na.rm = TRUE), n = n()) %>% 
  arrange(time)

dd
```


```{r}
collect(dd)
```


## Good for large simulations

This workflow is particularly useful when running replicate simulations in 
parallel, with large outputs

```{r}
library(future.apply, quietly = TRUE)

plan(multisession, workers = 5L)

out2 <- future_lapply(1:10, \(x) { mrgsim_ds(mod, data) }, future.seed = TRUE)

out2 <- reduce_ds(out2)

```

Now there are 10x the number of rows (14.5M), but little change in object size.
```{r}
out2
```

```{r}
lobstr::obj_size(out2)
```



## Files on disk are automagically managed

All `arrow` files are stored in the `tempdir()` in parquet format

```{r}
list_temp()
```

This directory is eventually removed when the R session ends. Tools are provided
to manage the space.

```{r}
retain_temp(out2)

list_temp()
```


We also put a finalizer on each object so that, when it goes out of scope, 
the files are automatically cleaned up. 

First, run a bunch of simulations.


```{r, echo = FALSE, message = FALSE}
purge_temp()
```

```{r, message = FALSE}
plan(multisession, workers = 5L)

out1 <- mrgsim_ds(mod, data)
rename_ds(out1, "out1")

out2 <- future_lapply(1:10, \(x) { mrgsim_ds(mod, data) }, future.seed = TRUE)

out2 <- reduce_ds(out2)
rename_ds(out2, "out2")

out3 <- mrgsim_ds(mod, data) 
rename_ds(out3, "out3")
```

There are 12 files holding simulation outputs. 

```{r}
list_temp()
```

Now, remove one of the objects containing 10 files.

```{r}
rm(out2)
```

As soon as the garbage collector is called, the leftover files are cleaned up.
```{r}
gc()

list_temp()
```


### Ownership 

This setup is only possible if one object owns the files on disk and `mrgsim.ds`
tracks this.

```{r}
ownership()
```

If I make a copy of a simulation object, the old object no longer owns the 
files. 

```{r}
out4 <- copy_ds(out1, own = TRUE)

check_ownership(out1)

check_ownership(out4)
```

I can always take ownership back. 
```{r}
take_ownership(out1)

check_ownership(out1)

check_ownership(out4)
```

## Simulation in parallel

Some special handling is required when simulations are actually run in an R 
session different from the one where the model was loaded and where simulation
outputs will be processed. One key example of this situation is simulation 
in parallel, especially when worker nodes are different R processes. 

For example, we can run this simulation in parallel. 


```{r, eval = using.parallel}
library(mirai)

mod <- modlib_ds("popex", end = 72)

data <- evd_expand(amt = 100, ID = 1:6)

daemons(3)

out <- mirai_map(
  1:3, 
  \(x, mod, data) { mrgsim.ds::mrgsim_ds(mod, data) },
  .args = list(mod = mod, data = data)
)[]

daemons(0)
```

First, notice that we used `modlib_ds()` rather than `mrgsolve::modlib()`. The 
resulting object has the important information tucked away to safely simulate
in parallel. 

Now look at the output. When we print the object to the console, you will see
that `mrgsim.ds` recognizes that the object was created in a different R 
process and updates `pid` as well as the pointer to the `arrow` data set:


```{r, eval = using.parallel}
out[[1]]
```

I refer to this as "refreshing" the output: relocate back on the parent R 
process and re-create the pointer to the data on disk. 

You can refresh a list of simulations like this

```{r, eval = using.parallel}
out <- refresh_ds(out)
```

This will get you relocated back on the parent R process. Better yet, you 
should call `reduce_ds()`

```{r, eval = using.parallel}
out <- reduce_ds(out)
```

This refreshes the simulation output objects _and_ collects them into a 
single object

```{r, eval = using.parallel}
out
```

Now we have all three files collected in a single object that we can work with

```{r parallel_output, eval = using.parallel, fig.height = 4, fig.width = 5, out.width = "80%", fig.align = "center"}
plot(out, IPRED ~ time, nid = 5)
```


### Details

`mrgsim.ds` tracks the `tempdir()` location and the process ID (via 
`Sys.getpid()`) of the R process where the model was loaded. When simulation 
outputs are saved to file, the save location is always `tempdir()` from that 
parent R process. When simulating in parallel, this will likely be _different_
than what  a call to `tempdir()` says on the worker node. 

At the time simulations are saved, the current R process id (`pid`) is saved
to the simulation output object. In the parallel simulation case, this will be 
different than the `pid` from the parent R process, saved in the model 
object. The finalizer function for a simulation object which removes output 
files from disk when the object goes out of scope is only run when the finalizer
is called from the parent R process as determined by `Sys.getpid()`. 





## If this is so great, why not make it the default for mrgsolve?

There is a cost to all of this. For small to mid-size simulations, you might 
see a small slowdown with `mrgsim_ds()`; it definitely won't be faster than 
`mrgsim()` ... even with the super-quick arrow ecosystem. This workflow is 
really for large simulation volumes where you are happy to pay the cost of 
writing outputs to file and then streaming them back in to summarize. 
